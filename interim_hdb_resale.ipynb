{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f29e44-4f92-4b7b-9387-d5479189df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sqlalchemy_utils\n",
    "#!pip install kaggle\n",
    "#!pip install streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d69994-b220-41fe-9b66-ef3419fa285c",
   "metadata": {},
   "source": [
    "# ðŸ“Š Project HDB Resale Hackers: Extract Transform Load\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d9d46c-d032-47bf-a90a-dda03f2b2570",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## <font color='blue'>**Step 1** </font> - Import Python modules\n",
    "\n",
    "| Import Statement | Purpose |\n",
    "| :--- | :--- |\n",
    "| `import os` | Used to talk to the computer's operating system. It lets the notebook do things like checking file paths and creating folders where the data will be saved.|\n",
    "| `from kaggle.api.kaggle_api_extended import KaggleApi` | Imports the specific tool needed to connect to Kaggle. This object handles authentication and allows us to run commands (like downloading datasets) directly from the notebook. |\n",
    "| `import pandas as pd` | Essential for **data manipulation** and analysis. Used for working with **DataFrames** (tabular data structure). |\n",
    "| `import time` | Provides various time-related functions. Often used to measure the **execution time (performance)** of code blocks, especially database operations. |\n",
    "| `import sqlalchemy as db` | The main SQLAlchemy library. Used for accessing fundamental types and functions (though often redundant if specific modules are imported). |\n",
    "| `from sqlalchemy import create_engine` | The key function to **establish a connection** to a database (e.g., SQLite, PostgreSQL, MySQL). |\n",
    "| `from sqlalchemy import text` | Used to wrap **raw SQL strings** when executing them directly via SQLAlchemy, allowing for easier parameter binding and compatibility. |\n",
    "| `from sqlalchemy_utils import create_database` | A helper function to easily **create a new database** if it doesn't already exist. |\n",
    "| `from sqlalchemy_utils import database_exists` | A utility function to **check if a database** with a given connection URL **exists**. |\n",
    "| `from typing import List` | Imports the List type, used to hint that a variable should be a list containing a specific type of elements (e.g., List[str]). |\n",
    "| `from typing import Dict` | Imports the Dict type, used to hint that a variable should be a dictionary with specific key and value types (e.g., Dict[str, int]). |\n",
    "| `import streamlit` | Used for interactive UI and dashboard pages, cache DB engine and display metrics, tables and charts |\n",
    "| `import altair` | Used to visualisations integrated into Streamlit for line chart, bar chart and integrates with pandas DataFrame and Streamlit. |\n",
    "| `import numpy` | Used for numeric transformations. |\n",
    "| `import psycopg2` | Used as PostgreSQL database driver between Python applications and the PostgreSQL relational database. |\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd24d38-9dbb-4286-9df5-6365f1a0fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import pandas as pd\n",
    "import time\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import create_database\n",
    "from sqlalchemy_utils import database_exists\n",
    "from sqlalchemy import text\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731dabfe-4415-4434-89cc-d62b1fad1a95",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <font color='blue'>**Step 2** </font> - Retrieve resale_hdb Dataset from Kaggle\n",
    "\n",
    "The dataset, sourced from **Kaggle** Dataset URL: https://www.kaggle.com/datasets/lzytim/hdb-resale-prices, contains Singapore Resale Flat Prices (Jan-17 to Sep-25).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd611e2f-1aa2-474b-8778-ba313aa1b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create kaggle folder to store kaggle api token\n",
    "#import os\n",
    "\n",
    "if not os.path.exists('.kaggle'):\n",
    "    os.makedirs('.kaggle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8e23c33-6832-4ef7-85fa-504ce7c0d532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset lzytim/hdb-resale-prices...\n",
      "Dataset URL: https://www.kaggle.com/datasets/lzytim/hdb-resale-prices\n",
      "Dataset lzytim/hdb-resale-prices downloaded to ./datasets\n",
      "   Unnamed: 0       month        town blk_no             road_name building  \\\n",
      "0           0  2017-01-01  ANG MO KIO    406  ANG MO KIO AVENUE 10      NIL   \n",
      "\n",
      "   postal  resale_price storey_range flat_type  ...             y  latitude  \\\n",
      "0  560406      232000.0     10 TO 12    2 ROOM  ...  38229.067463  1.362005   \n",
      "\n",
      "   longitude  closest_mrt_station  distance_to_mrt_meters  transport_type  \\\n",
      "0  103.85388           Ang Mo Kio              999.941618             MRT   \n",
      "\n",
      "   line_color distance_to_cbd         closest_pri_school  \\\n",
      "0         Red     8615.656983  TOWNSVILLE PRIMARY SCHOOL   \n",
      "\n",
      "   distance_to_pri_school_meters  \n",
      "0                     218.125254  \n",
      "\n",
      "[1 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "def download_kaggle_dataset(dataset_name, download_path=\"datasets\"):\n",
    "    \"\"\"\n",
    "    Downloads a dataset from Kaggle using Kaggle API.\n",
    "\n",
    "    :param dataset_name: Name of the Kaggle dataset (e.g. 'xyz/some-dataset-name').\n",
    "    :param download_path: Path where to save the downloaded dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make the download path if it doesn't exist (the 'datasets' and '.kaggle' folder)\n",
    "    if not os.path.exists(download_path):\n",
    "        os.makedirs(download_path)\n",
    "    if not os.path.exists('.kaggle'):\n",
    "        os.makedirs('.kaggle')\n",
    "\n",
    "\n",
    "    # Set up Kaggle API client\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    \n",
    "    # Download the dataset\n",
    "    print(f\"Downloading dataset {dataset_name}...\")\n",
    "    api.dataset_download_files(dataset_name, path=download_path, unzip=True)\n",
    "    print(f\"Dataset {dataset_name} downloaded to {download_path}\")\n",
    "\n",
    "def load_csv_from_dataset(download_path, csv_filename):\n",
    "    \"\"\"\n",
    "    Loads a CSV file from a downloaded dataset.\n",
    "\n",
    "    :param download_path: Path where the dataset was downloaded.\n",
    "    :param csv_filename: Name of the CSV file to load.\n",
    "    \"\"\"\n",
    "    # Construct the full path to the CSV file\n",
    "    csv_file_path = os.path.join(download_path, csv_filename)\n",
    "\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "dataset_name = 'lzytim/hdb-resale-prices'  # Replace this with the actual Kaggle dataset identifier\n",
    "download_path = './datasets'  # Path where you want the dataset to be downloaded\n",
    "\n",
    "# Download the dataset\n",
    "download_kaggle_dataset(dataset_name, download_path)\n",
    "\n",
    "# Detect .csv and add name of csv file to csv_filename\n",
    "entries = os.listdir('datasets')\n",
    "for n in entries:\n",
    "    if '.csv' in n:\n",
    "        csv_filename = n\n",
    "\n",
    "# Load the CSV file\n",
    "df = load_csv_from_dataset(download_path, csv_filename)\n",
    "\n",
    "# Show first few rows of the DataFrame\n",
    "print(df.head(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15514d6b-65e0-4be6-afe3-e743108078f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <font color='blue'>**Step 3** </font> - Retrieve MRT LRT Dataset from Kaggle\n",
    "\n",
    "The dataset, sourced from **Kaggle** Dataset URL: https://www.kaggle.com/datasets/lzytim/hdb-resale-prices, contains Singapore Resale Flat Prices (Jan-17 to Sep-25).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36eb4631-8074-412e-92ce-3a207788f988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset lzytim/full-list-of-mrt-and-lrt-stations-in-singapore...\n",
      "Dataset URL: https://www.kaggle.com/datasets/lzytim/full-list-of-mrt-and-lrt-stations-in-singapore\n",
      "Dataset lzytim/full-list-of-mrt-and-lrt-stations-in-singapore downloaded to ./train_datasets\n",
      "         station transport_type line_color\n",
      "0    Jurong East            MRT        Red\n",
      "1    Bukit Batok            MRT        Red\n",
      "2   Bukit Gombak            MRT        Red\n",
      "3  Choa Chu Kang            MRT        Red\n",
      "4        Yew Tee            MRT        Red\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "dataset_train_name = \"lzytim/full-list-of-mrt-and-lrt-stations-in-singapore\"  # Replace this with the actual Kaggle dataset identifier\n",
    "download_train_path = './train_datasets'  # Path where you want the dataset to be downloaded\n",
    "\n",
    "# Download the dataset\n",
    "download_kaggle_dataset(dataset_train_name, download_train_path)\n",
    "\n",
    "# Detect .csv and add name of csv file to csv_filename\n",
    "entries = os.listdir('train_datasets')\n",
    "for n in entries:\n",
    "    if '.csv' in n:\n",
    "        csv_filename = n\n",
    "\n",
    "# Load the CSV file\n",
    "trains_df = load_csv_from_dataset(download_train_path, csv_filename)\n",
    "\n",
    "# Show first few rows of the DataFrame\n",
    "\n",
    "trains_df = trains_df[['station_name', 'type', 'color']]\n",
    "trains_df.rename(columns={'station_name': 'station', 'type': 'transport_type', 'color': 'line_color'}, inplace=True)\n",
    "\n",
    "print(trains_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1dba3b-3207-42bd-9f9b-dc850bd36e5e",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## <font color='blue'>**Step 4** </font> - Setup postgreSQL Connection details\n",
    "\n",
    "* Define pg_config with postgres connection details.\n",
    "* Define variables containing the Database name, tablenames that are to be created and used for this project.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "732e22c7-215e-445f-a111-72ae1eb1dd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Connection details / DB_Name / Table_name\n",
    "# -------------------------------------------------------------\n",
    "pg_config = {\n",
    "    'host': 'localhost',\n",
    "    'port': 5432,\n",
    "    'user': 'postgres',\n",
    "    'password': 'admin'\n",
    "}\n",
    "\n",
    "new_db_name = \"hdb_db\"\n",
    "table_name = \"resale_hdb\"\n",
    "town_tablename = 'towns'\n",
    "trains_tablename = 'trains'\n",
    "stations_tablename = 'stations'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6733d3b3-42f4-4f51-85f2-d745a6ce1370",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## <font color='blue'>**Step 5** </font> - Create postgresql DB if not exists (hdb_db)\n",
    "\n",
    "* Check if database name hdb_db already exists\n",
    "* Create new DB with database name if not exists\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e1d126c-0e71-4144-afc5-e31cd4f7f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_postgresql_database(pg_config: dict, new_db_name: str):\n",
    "    # 1. Construct the connection URL\n",
    "    # NOTE: We construct the URL without the DB name first, as the DB must exist to connect.\n",
    "    # We then add the new_db_name to the URL object for the existence check.\n",
    "    base_url = f\"postgresql://{pg_config['user']}:{pg_config['password']}@{pg_config['host']}:{pg_config['port']}\"\n",
    "    \n",
    "    # 2. Create the engine object\n",
    "    # We create the engine pointing to the target database URL\n",
    "    engine = create_engine(f\"{base_url}/{new_db_name}\")\n",
    "\n",
    "    # 3. Check for existence and create\n",
    "    try:\n",
    "        if not database_exists(engine.url):\n",
    "            create_database(engine.url)\n",
    "            print(f\"Database '{new_db_name}' created successfully.\")\n",
    "        else:\n",
    "            print(f\"Database '{new_db_name}' already exists.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during database creation: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        # 4. Release resources associated with the engine\n",
    "        engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0da2b61-c24d-4544-a5e1-a12ba9741825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'hdb_db' already exists.\n"
     ]
    }
   ],
   "source": [
    "# ----- Function - call ----- #\n",
    "create_postgresql_database(pg_config, new_db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3c2663-c13b-45ba-8e44-9bd1c408c7c3",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# <font color='blue'>**Step 6** </font> - Assign Kaggle dataframe to RAWDATA dataframe\n",
    "\n",
    "* This assign the dataframe from Kaggle in step2 to dataframe rawdata.\n",
    "* This assignment is for integration testing as we are working on the 2 parts individually.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b74122d-246d-485c-8423-16f7bd9334f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle resale hdb dataframe file loaded to rawdata dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>month</th>\n",
       "      <th>town</th>\n",
       "      <th>blk_no</th>\n",
       "      <th>road_name</th>\n",
       "      <th>building</th>\n",
       "      <th>postal</th>\n",
       "      <th>resale_price</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>...</th>\n",
       "      <th>y</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>closest_mrt_station</th>\n",
       "      <th>distance_to_mrt_meters</th>\n",
       "      <th>transport_type</th>\n",
       "      <th>line_color</th>\n",
       "      <th>distance_to_cbd</th>\n",
       "      <th>closest_pri_school</th>\n",
       "      <th>distance_to_pri_school_meters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>406</td>\n",
       "      <td>ANG MO KIO AVENUE 10</td>\n",
       "      <td>NIL</td>\n",
       "      <td>560406</td>\n",
       "      <td>232000.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>2 ROOM</td>\n",
       "      <td>...</td>\n",
       "      <td>38229.067463</td>\n",
       "      <td>1.362005</td>\n",
       "      <td>103.85388</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>999.941618</td>\n",
       "      <td>MRT</td>\n",
       "      <td>Red</td>\n",
       "      <td>8615.656983</td>\n",
       "      <td>TOWNSVILLE PRIMARY SCHOOL</td>\n",
       "      <td>218.125254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       month        town blk_no             road_name building  \\\n",
       "0           0  2017-01-01  ANG MO KIO    406  ANG MO KIO AVENUE 10      NIL   \n",
       "\n",
       "   postal  resale_price storey_range flat_type  ...             y  latitude  \\\n",
       "0  560406      232000.0     10 TO 12    2 ROOM  ...  38229.067463  1.362005   \n",
       "\n",
       "   longitude  closest_mrt_station  distance_to_mrt_meters  transport_type  \\\n",
       "0  103.85388           Ang Mo Kio              999.941618             MRT   \n",
       "\n",
       "   line_color distance_to_cbd         closest_pri_school  \\\n",
       "0         Red     8615.656983  TOWNSVILLE PRIMARY SCHOOL   \n",
       "\n",
       "   distance_to_pri_school_meters  \n",
       "0                     218.125254  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#rawdata = pd.read_csv(csv_file)\n",
    "rawdata = df\n",
    "print(\"Kaggle resale hdb dataframe file loaded to rawdata dataframe:\")\n",
    "\n",
    "rawdata.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b6ec5e-6765-4b4f-beb9-52547ccb7957",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## <font color='blue'>**Step 7** </font> - Create TRAINS, STATIONS, TOWNS, HDB_RESALE tables in postgresql\n",
    "\n",
    "* Drop all tables before recreation\n",
    "* STATIONS - to contain all the station names\n",
    "* TRAINS - to contain all the train type (MRT, LRT) and line color information.\n",
    "* TOWNS - to contain town name, region_ura, planning_area_ura information (subset from resale hdb transactions file)\n",
    "* RESALE_HDB - to contain all main information regarding HDB resale transactions\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99883a9d-82af-4088-b988-c84482bb64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql_commands(pg_config: Dict, db_name: str, sql_commands: List[str]):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pg_config (Dict): Dictionary with PostgreSQL connection details \n",
    "                          ('user', 'password', 'host', 'port').\n",
    "        db_name (str): The name of the target database where commands will run.\n",
    "        sql_commands (List[str]): A list of SQL strings to be executed.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Construct the connection URL\n",
    "    try:\n",
    "        db_url = (\n",
    "            f\"postgresql://{pg_config['user']}:{pg_config['password']}@\"\n",
    "            f\"{pg_config['host']}:{pg_config['port']}/{db_name}\"\n",
    "        )\n",
    "        \n",
    "        # 2. Create the engine\n",
    "        engine = create_engine(db_url)\n",
    "\n",
    "        # 3. Execute commands within a transaction\n",
    "        # engine.begin() manages the transaction, commits on success, rolls back on error\n",
    "        with engine.begin() as conn:\n",
    "            print(f\"Executing commands on database '{db_name}'...\")\n",
    "            for i, command in enumerate(sql_commands):\n",
    "                # Using text() is best practice for executing raw SQL strings\n",
    "                conn.execute(text(command))\n",
    "                print(f\"  > SQL Command {i+1}/{len(sql_commands)} executed.\")\n",
    "        \n",
    "        print(\"All SQL commands executed successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during SQL execution: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        # 4. Release resources\n",
    "        if 'engine' in locals() and engine:\n",
    "            engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64f23238-c329-4f81-8caf-305efa5cf3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing commands on database 'hdb_db'...\n",
      "  > SQL Command 1/5 executed.\n",
      "  > SQL Command 2/5 executed.\n",
      "  > SQL Command 3/5 executed.\n",
      "  > SQL Command 4/5 executed.\n",
      "  > SQL Command 5/5 executed.\n",
      "All SQL commands executed successfully.\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(\n",
    "    f\"postgresql://{pg_config['user']}:{pg_config['password']}@{pg_config['host']}:{pg_config['port']}/{new_db_name}\"\n",
    ")\n",
    "\n",
    "sql_commands = ['''\n",
    "    DROP TABLE IF EXISTS stations CASCADE;\n",
    "    CREATE TABLE stations(\n",
    "        station_id SERIAL PRIMARY KEY,\n",
    "        station VARCHAR UNIQUE NOT NULL\n",
    "        );\n",
    "    ''',\n",
    "    '''\n",
    "    DROP TABLE IF EXISTS trains CASCADE;\n",
    "    CREATE TABLE trains(\n",
    "        id SERIAL PRIMARY KEY ,\n",
    "        station VARCHAR REFERENCES stations(station),\n",
    "        transport_type VARCHAR,\n",
    "        line_color VARCHAR,\n",
    "        UNIQUE (station, transport_type, line_color)\n",
    "    );\n",
    "   ''',\n",
    "   '''             \n",
    "    DROP TABLE IF EXISTS towns CASCADE;\n",
    "    CREATE TABLE towns(\n",
    "        town_id INT PRIMARY KEY,\n",
    "        town VARCHAR,\n",
    "        planning_area_ura VARCHAR,\n",
    "        region_ura VARCHAR\n",
    "    );\n",
    "   ''',\n",
    "   '''\n",
    "    DROP TABLE IF EXISTS resale_hdb CASCADE;  \n",
    "    CREATE TABLE resale_hdb(   \n",
    "        resale_id SERIAL PRIMARY KEY,\n",
    "        month date,\n",
    "        postal text,\n",
    "        resale_price int,\n",
    "        storey_range text,\n",
    "        flat_type text,\n",
    "        flat_model text,\n",
    "        remaining_lease_years int,\n",
    "        floor_area_sqft numeric,\n",
    "        price_per_sqft numeric,\n",
    "        latitude numeric,\n",
    "        longitude numeric,\n",
    "        closest_mrt_station text REFERENCES stations(station),\n",
    "        distance_to_mrt_meters numeric,\n",
    "        distance_to_cbd numeric,\n",
    "        closest_pri_school text,\n",
    "        distance_to_pri_school_meters numeric,\n",
    "        town_id int REFERENCES towns(town_id)\n",
    "    );\n",
    "   ''',\n",
    "   '''\n",
    "   CREATE INDEX idx_trains_station ON trains(station);\n",
    "   CREATE INDEX idx_resale_station ON resale_hdb(closest_mrt_station);\n",
    "   '''\n",
    "]\n",
    "\n",
    "# ----- Function - call ----- #\n",
    "execute_sql_commands(pg_config, new_db_name, sql_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e222a903-8e7e-4574-9085-a55182d7bb9f",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## <font color='blue'>**Step 8** </font> - Assign Kaggle MRT LRT dataset to Train dataframe\n",
    "\n",
    "* load to trains dataframe\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5abec10-8b3d-4362-a7db-41a266532d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>transport_type</th>\n",
       "      <th>line_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jurong East</td>\n",
       "      <td>MRT</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bukit Batok</td>\n",
       "      <td>MRT</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station transport_type line_color\n",
       "0  Jurong East            MRT        Red\n",
       "1  Bukit Batok            MRT        Red"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distinct_train_df = pd.read_csv(trains_csv_file) -- assign from Kaggle dataset\n",
    "distinct_train_df = trains_df\n",
    "distinct_train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6cdf56-d30d-41d1-a2ea-3742a3ab612d",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## <font color='blue'>**Step 9** </font> - **Load** dataframe to Trains and Stations Table\n",
    "* Stations.station_id is SERIAL type\n",
    "* Trains.id is SERIAL type\n",
    "\n",
    "info\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9451df70-ab44-4d47-a279-c1edc6ae21ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'trains' and 'stations' data loaded successfully!\n",
      "Runtime: 0.2331 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to check, remove duplicates\n",
    "subset_distinct_train_df = distinct_train_df[['station','transport_type','line_color']].drop_duplicates()\n",
    "\n",
    "# Define the columns to check, remove duplicates\n",
    "subset_distinct_stations_df = distinct_train_df['station'].drop_duplicates()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "subset_distinct_stations_df.to_sql(stations_tablename, engine, if_exists=\"append\", index=False)\n",
    "subset_distinct_train_df.to_sql(trains_tablename, engine, if_exists=\"append\", index=False)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Table '{trains_tablename}' and '{stations_tablename}' data loaded successfully!\")\n",
    "print(f\"Runtime: {end - start:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7b37e-fcb3-41ca-a137-1ce087d412bf",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## <font color='blue'>**Step 10** </font> - Create subset TOWNS dataframe from RAWDATA dataframe\n",
    "* Create Towns dataframe with a subset from original dataframe, rawdata\n",
    "* Assigned town_id to the new town dataframe\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7451d4ba-cb99-45b0-9f63-95ecbcb8041e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>town_id</th>\n",
       "      <th>town</th>\n",
       "      <th>planning_area_ura</th>\n",
       "      <th>region_ura</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>NORTH-EAST REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BEDOK</td>\n",
       "      <td>BEDOK</td>\n",
       "      <td>EAST REGION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   town_id        town planning_area_ura         region_ura\n",
       "0        1  ANG MO KIO        ANG MO KIO  NORTH-EAST REGION\n",
       "1        2       BEDOK             BEDOK        EAST REGION"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_town_df = rawdata[['town', 'planning_area_ura', 'region_ura']].drop_duplicates().sort_values('town')\n",
    "\n",
    "distinct_town_df = distinct_town_df.reset_index(drop=True)\n",
    "distinct_town_df.insert(0, \"town_id\", range(1, len(distinct_town_df) + 1))\n",
    "\n",
    "distinct_town_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cbfa1f-e339-4e9d-866b-dba6235852da",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## <font color='blue'>**Step 11** </font> - Update Town_id (from allocated TOWNS dataframe) to rawdata_with_town_id dataframe\n",
    "\n",
    "* Reassign town_id back to original dataframe data\n",
    "* Foriegn key on main table town_id referencing towns town_id to ensure data integrity \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff60873d-b6b5-40e7-9f40-489041f10837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>month</th>\n",
       "      <th>town</th>\n",
       "      <th>blk_no</th>\n",
       "      <th>road_name</th>\n",
       "      <th>building</th>\n",
       "      <th>postal</th>\n",
       "      <th>resale_price</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>...</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>closest_mrt_station</th>\n",
       "      <th>distance_to_mrt_meters</th>\n",
       "      <th>transport_type</th>\n",
       "      <th>line_color</th>\n",
       "      <th>distance_to_cbd</th>\n",
       "      <th>closest_pri_school</th>\n",
       "      <th>distance_to_pri_school_meters</th>\n",
       "      <th>town_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>406</td>\n",
       "      <td>ANG MO KIO AVENUE 10</td>\n",
       "      <td>NIL</td>\n",
       "      <td>560406</td>\n",
       "      <td>232000.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>2 ROOM</td>\n",
       "      <td>...</td>\n",
       "      <td>1.362005</td>\n",
       "      <td>103.85388</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>999.941618</td>\n",
       "      <td>MRT</td>\n",
       "      <td>Red</td>\n",
       "      <td>8615.656983</td>\n",
       "      <td>TOWNSVILLE PRIMARY SCHOOL</td>\n",
       "      <td>218.125254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       month        town blk_no             road_name building  \\\n",
       "0           0  2017-01-01  ANG MO KIO    406  ANG MO KIO AVENUE 10      NIL   \n",
       "\n",
       "   postal  resale_price storey_range flat_type  ...  latitude  longitude  \\\n",
       "0  560406      232000.0     10 TO 12    2 ROOM  ...  1.362005  103.85388   \n",
       "\n",
       "   closest_mrt_station  distance_to_mrt_meters  transport_type  line_color  \\\n",
       "0           Ang Mo Kio              999.941618             MRT         Red   \n",
       "\n",
       "   distance_to_cbd         closest_pri_school distance_to_pri_school_meters  \\\n",
       "0      8615.656983  TOWNSVILLE PRIMARY SCHOOL                    218.125254   \n",
       "\n",
       "   town_id  \n",
       "0        1  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata_with_town_id = rawdata.merge(\n",
    "    distinct_town_df[['town', 'planning_area_ura', 'region_ura', 'town_id']],\n",
    "    on=['town', 'planning_area_ura', 'region_ura'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "rawdata_with_town_id.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f89b99a-7c95-448b-911d-395fc44d7682",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## <font color='blue'>**Step 12** </font> - **Load** Towns dataframe to Towns table\n",
    "\n",
    "* loading dataframe to postgresql table\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8e0c737-8382-4f2e-b86e-6ecd84ac8360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'towns' created and CSV data loaded successfully!\n",
      "Runtime: 0.0128 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "distinct_town_df.to_sql(town_tablename, engine, if_exists=\"append\", index=False)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Table '{town_tablename}' created and CSV data loaded successfully!\")\n",
    "print(f\"Runtime: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8f352c-1ecb-4309-bbcb-f1ca05bb532c",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## <font color='blue'>**Step 13** </font> - Data Cleaning - remove unnecessary data columns\n",
    "\n",
    "* **Data fields to be excluded**\n",
    "  * unnamed\n",
    "  * 'blk_no', \n",
    "  * 'road_name', \n",
    "  * 'building', \n",
    "  * 'lease_commence_date',\n",
    "  * 'remaining_lease_months',\n",
    "  * 'floor_area_sqm',\n",
    "  * 'x',\n",
    "  * 'y',\n",
    "  * 'town', \n",
    "  * 'planning_area_ura', \n",
    "  * 'region_ura', \n",
    "  * 'transport_type', \n",
    "  * 'line_color'\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86e26cac-aaf1-4cd8-bd97-734903edd04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>postal</th>\n",
       "      <th>resale_price</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>remaining_lease_years</th>\n",
       "      <th>floor_area_sqft</th>\n",
       "      <th>price_per_sqft</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>closest_mrt_station</th>\n",
       "      <th>distance_to_mrt_meters</th>\n",
       "      <th>distance_to_cbd</th>\n",
       "      <th>closest_pri_school</th>\n",
       "      <th>distance_to_pri_school_meters</th>\n",
       "      <th>town_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>560406</td>\n",
       "      <td>232000.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>2 ROOM</td>\n",
       "      <td>Improved</td>\n",
       "      <td>61</td>\n",
       "      <td>473.6116</td>\n",
       "      <td>489.852867</td>\n",
       "      <td>1.362005</td>\n",
       "      <td>103.85388</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>999.941618</td>\n",
       "      <td>8615.656983</td>\n",
       "      <td>TOWNSVILLE PRIMARY SCHOOL</td>\n",
       "      <td>218.125254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        month  postal  resale_price storey_range flat_type flat_model  \\\n",
       "0  2017-01-01  560406      232000.0     10 TO 12    2 ROOM   Improved   \n",
       "\n",
       "   remaining_lease_years  floor_area_sqft  price_per_sqft  latitude  \\\n",
       "0                     61         473.6116      489.852867  1.362005   \n",
       "\n",
       "   longitude closest_mrt_station  distance_to_mrt_meters  distance_to_cbd  \\\n",
       "0  103.85388          Ang Mo Kio              999.941618      8615.656983   \n",
       "\n",
       "          closest_pri_school  distance_to_pri_school_meters  town_id  \n",
       "0  TOWNSVILLE PRIMARY SCHOOL                     218.125254        1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# the first original column is \"unnamed\"\n",
    "# This is to remove that column before write data to postgres database\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "unnamed_cols = [col for col in rawdata_with_town_id.columns if 'Unnamed' in col]\n",
    "drop_col_df = rawdata_with_town_id[unnamed_cols]\n",
    "data_df = rawdata_with_town_id.drop(columns=unnamed_cols)\n",
    "\n",
    "cols_to_exclude = ['blk_no', \n",
    "                   'road_name', \n",
    "                   'building', \n",
    "                   'lease_commence_date',\n",
    "                   'remaining_lease_months',\n",
    "                   'floor_area_sqm',\n",
    "                   'x',\n",
    "                   'y',\n",
    "                   'town', \n",
    "                   'planning_area_ura', \n",
    "                   'region_ura', \n",
    "                   'transport_type', \n",
    "                   'line_color']\n",
    "data_df = data_df.drop(columns=cols_to_exclude)\n",
    "\n",
    "data_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e31c37-f68f-4a3c-9a31-50664ea6e412",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## <font color='blue'>**Step 14** </font> - Data Cleaning - data formatting\n",
    "\n",
    "* Convert Postal code to str type and ensure length of 6\n",
    "* Convert to 2 decimal place\n",
    "    * floor_area_sqft\n",
    "    * price_per_sqft,\n",
    "    * distance_to_mrt_meters\n",
    "    * distance_to_cbd\n",
    "    * distance_to_pri_school_meters\n",
    "* Trim text variables\n",
    "    *  closest_pri_school\n",
    "    *  flat_model\n",
    "* Check stations names matches stations list\n",
    "  \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d33db82-ce36-4840-85ce-2646c88f2fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning 2540 postal details:\n",
      "num of train stations names incorrect records 4\n",
      "             month  postal  resale_price storey_range flat_type  \\\n",
      "199094  2025-04-01  650265      400000.0     01 TO 03    3 ROOM   \n",
      "199096  2025-05-01  650259      410000.0     04 TO 06    3 ROOM   \n",
      "199100  2025-08-01  650265      430000.0     04 TO 06    3 ROOM   \n",
      "199103  2025-09-01  650265      427000.0     07 TO 09    3 ROOM   \n",
      "\n",
      "            flat_model  remaining_lease_years  floor_area_sqft  \\\n",
      "199094  New Generation                     59           721.18   \n",
      "199096  New Generation                     59           721.18   \n",
      "199100  New Generation                     59           882.64   \n",
      "199103  New Generation                     59           882.64   \n",
      "\n",
      "        price_per_sqft  latitude   longitude closest_mrt_station  \\\n",
      "199094          554.65  1.350008  103.759863                Hume   \n",
      "199096          568.51  1.350859  103.759761                Hume   \n",
      "199100          487.17  1.350008  103.759863                Hume   \n",
      "199103          483.78  1.350008  103.759863                Hume   \n",
      "\n",
      "        distance_to_mrt_meters  distance_to_cbd     closest_pri_school  \\\n",
      "199094                 1148.19         12529.56  KEMING PRIMARY SCHOOL   \n",
      "199096                 1120.38         12593.63  KEMING PRIMARY SCHOOL   \n",
      "199100                 1148.19         12529.56  KEMING PRIMARY SCHOOL   \n",
      "199103                 1148.19         12529.56  KEMING PRIMARY SCHOOL   \n",
      "\n",
      "        distance_to_pri_school_meters  town_id  \n",
      "199094                         624.25        4  \n",
      "199096                         695.12        4  \n",
      "199100                         624.25        4  \n",
      "199103                         624.25        4  \n"
     ]
    }
   ],
   "source": [
    "# Convert Postal code to str type and ensure length of 6\n",
    "data_df['postal'] = data_df['postal'].astype(str)\n",
    "postal_mask = data_df['postal'].str.len() < 6\n",
    "\n",
    "if len(data_df[postal_mask]) > 0:\n",
    "    print(f\"Cleaning {len(data_df[postal_mask])} postal details:\")\n",
    "    data_df['postal'] = data_df['postal'].str.zfill(6)\n",
    "else:\n",
    "    print(\"postal data checked ok ...\")\n",
    "\n",
    "# floor_area_sqft\n",
    "data_df['floor_area_sqft'] = data_df['floor_area_sqft'].round(2)\n",
    "\n",
    "# price_per_sqft  -- enhance next time to financial round up\n",
    "data_df['price_per_sqft'] = data_df['price_per_sqft'].round(2)\n",
    "\n",
    "#distance_to_mrt_meters (xx decimal place)\n",
    "data_df['distance_to_mrt_meters'] = data_df['distance_to_mrt_meters'].round(2)\n",
    "\n",
    "#distance_to_cbd (xx decimal place)\n",
    "data_df['distance_to_cbd'] = data_df['distance_to_cbd'].round(2)\n",
    "\n",
    "#distance_to_pri_school_meters (xx decimal place)\n",
    "data_df['distance_to_pri_school_meters'] = data_df['distance_to_pri_school_meters'].round(2)\n",
    "\n",
    "#TRIM text cleaning\n",
    "#closest_pri_school(TRIM)\n",
    "data_df['closest_pri_school'] = data_df['closest_pri_school'].str.strip()\n",
    "\n",
    "#flat_model(Trim)\n",
    "data_df['flat_model'] = data_df['flat_model'].str.strip()\n",
    "\n",
    "# closest_mrt_stations (check if exists in trains df )\n",
    "unclean_trains_df_mask = ~data_df['closest_mrt_station'].isin(subset_distinct_train_df['station'])\n",
    "unclean_trains_records = data_df[unclean_trains_df_mask]\n",
    "\n",
    "if len(unclean_trains_records) == 0:\n",
    "    print(\"train stations names check okay ... \")\n",
    "else:\n",
    "    print(f\"num of train stations names incorrect records {len(unclean_trains_records)}\")\n",
    "    print(unclean_trains_records.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a35c0-14b2-423c-8427-347f0cb31e3d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <font color='blue'>**Step 14.1** </font> - Data Cleaning - Due to Unclean Data in Step14.\n",
    "\n",
    "MRT LRT dataset lastest updated on is Jan 2025\n",
    "HDB Resale transactions Sep 2025\n",
    "To clean the data - \n",
    "This portion is to insert the latest station 'Hume' station.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c6010cd-905e-43ef-8853-f69da5512b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing commands on database 'hdb_db'...\n",
      "  > SQL Command 1/2 executed.\n",
      "  > SQL Command 2/2 executed.\n",
      "All SQL commands executed successfully.\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(\n",
    "    f\"postgresql://{pg_config['user']}:{pg_config['password']}@{pg_config['host']}:{pg_config['port']}/{new_db_name}\"\n",
    ")\n",
    "\n",
    "sql_commands = ['''\n",
    "        INSERT INTO stations (station) VALUES ('Hume');\n",
    "    ''',\n",
    "    '''\n",
    "        INSERT INTO trains (station, transport_type,\n",
    "        line_color)\n",
    "\t\tVALUES ('Hume', 'MRT', 'Blue');\n",
    "    '''\n",
    "    ]\n",
    "\n",
    "execute_sql_commands(pg_config, new_db_name, sql_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f219e-7d63-4aca-87b3-43f1ab0c62cf",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## <font color='blue'>**Step 15** </font> - **Load** dataframe to resale_hdb Table\n",
    "\n",
    "* Expected 217,001 records to be loaded \n",
    "* Expected loading time around 60-120 secs\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "005c7774-4f7b-4db3-aaeb-7bc5c09b7314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'resale_hdb' data loaded successfully!\n",
      "Runtime: 45.6591 seconds\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Load CSV data to table (new table or replace)\n",
    "# -------------------------------------------------------------\n",
    "start = time.time()\n",
    "\n",
    "data_df = data_df.reset_index(drop=True) \n",
    "data_df.index = data_df.index + 1        # shift to start at 1\n",
    "\n",
    "#data_df.to_sql(table_name, engine, if_exists=\"append\", index=True, index_label=\"resale_id\") \n",
    "data_df.to_sql(table_name, engine, if_exists=\"append\", index=False) \n",
    "end = time.time()\n",
    "\n",
    "print(f\"Table '{table_name}' data loaded successfully!\")\n",
    "print(f\"Runtime: {end - start:.4f} seconds\")\n",
    "\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc383584-51c3-43a6-81b2-3d054f409c0b",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## <font color='blue'>**Complete** </font>\n",
    "\n",
    "* Below data verification of the count of tables\n",
    "* Data can be accessed through postgresql database\n",
    "* Accessible to any other tools for data analyzing i.e. tableau\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4fa921-5571-4e23-bea2-724826d31aea",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## <font color='blue'>**Proceed next to streamlit app, Tableau data visualization** </font>\n",
    "\n",
    "* Next program - Streamlit app will access the data from postgres database\n",
    "* Tableau (next program) - access database for data analyzing data visualization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d785a368-78b2-4e05-a018-cab768593c15",
   "metadata": {},
   "source": [
    "# Extra Example - Using sqlalchemy to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2201130-7050-4c20-bb02-6f255c56d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"Select count(*) from resale_hdb\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d4abab-a2a7-48c5-a7d9-6d457e7d5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"select count(1) from towns\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb000c-7dc8-4765-b599-6d4ca76f2fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"select count(1) from trains\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23580f3-1d11-48dd-9b40-bff08bbc8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"select count(1) from stations\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc6bdbd-176b-46bb-9287-581b50ce91e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
